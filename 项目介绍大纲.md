# 基于图卷积网络的商品推荐系统 - 演讲大纲

## 幻灯片 1: 标题页
**标题：** 基于图卷积网络的商品推荐系统  
**副标题：** 让算法理解你的购物偏好  
**演讲者：** [你的姓名]

---

## 幻灯片 2: 推荐系统在生活中的应用
**内容：**
- 我们每天都在使用推荐系统
  - 淘宝/京东：猜你喜欢的商品
  - 抖音：推荐你可能感兴趣的视频
  - 网易云音乐：为你推荐可能喜欢的歌曲
  - B站：首页推荐视频

**关键问题：** 这些系统是如何知道你喜欢什么的？

---

## 幻灯片 3: 本项目要解决的问题
**场景：**
- 有一个电商平台，记录了用户购买或浏览过哪些商品
- 问题：如何给用户推荐他们还没买过，但可能会喜欢的商品？

**挑战：**
- 用户只会购买一小部分商品（数据非常稀疏）
- 我们没有评分数据，只知道"买过"或"没买过"
- 需要从这些有限的信息中找到规律

---

## 幻灯片 4: 我们的解决方案概述
**核心思想：**
- 把用户和商品的关系看成一个"社交网络"
- 通过图卷积网络（GCN）在这个网络上传播信息
- 使用BPR损失函数来学习用户的偏好

**两个核心技术：**
1. 图卷积网络（GCN）- 帮助我们理解用户和商品之间的关系
2. BPR损失函数 - 教会模型如何排序推荐

---

## 幻灯片 5: 什么是图？
**用通俗的话来解释：**
- 图就像一个"关系网络"
- **节点（圆圈）**：代表实体，比如人、商品、用户
- **边（连线）**：代表关系，比如"购买过"、"朋友"、"浏览过"

**我们的图：**
- 左边的节点：用户
- 右边的节点：商品
- 连线：表示某个用户购买或浏览过某个商品
- 这种图叫做"二部图"（用户和商品是两种不同类型的节点）

**示例图：**
```
用户A ---- 商品1
 |  \      /
 |    \  /
 |     X
 |   /  \
 | /      \
用户B ---- 商品2 ---- 用户C
```

---

## 幻灯片 6: 传统方法的局限
**协同过滤方法：**
- 思路："购买相同商品的用户，品味可能相似"
- 例如：用户A和用户B都买了iPhone，那么用户A还可能喜欢用户B买过的其他商品

**问题：**
- 只能捕捉到直接的相似关系
- 无法利用更复杂的网络结构
- 比如："用户A购买的商品 → 被用户B也购买 → 用户B购买的商品 → 被用户C也购买" 这种间接关系很难被发现

---

## 幻灯片 7: 图卷积网络（GCN）的核心思想
**关键理念：** "你的朋友会影响你的品味"

**在社交网络中：**
- 如果你的朋友都喜欢跑步，你也可能喜欢跑步
- 如果你关注的人都在讨论某部电影，你可能也会对它感兴趣

**在推荐系统中：**
- 如果一个商品被很多和你品味相似的用户购买，你也可能喜欢这个商品
- 如果一个用户购买的商品和你购买的商品相似，你可能也喜欢这个用户购买的其他商品

**GCN的作用：** 让信息在图上"流动"，每个节点会受到邻居节点的影响

---

## 幻灯片 8: GCN如何工作 - 嵌入向量
**什么是嵌入向量？**
- 可以把它想象成每个用户/商品的"特征指纹"
- 是一串数字（比如64个数字），表示这个用户/商品的特点
- 例如：`[0.2, -0.5, 0.8, ..., 0.1]` （共64个数）

**为什么需要嵌入向量？**
- 计算机无法直接理解"用户"和"商品"
- 需要把它们转换成数字，才能进行计算
- 相似的用户应该有相似的向量，相似的商品也应该有相似的向量

**初始化：**
- 一开始，我们给每个用户和商品随机分配一个向量
- 这些向量在训练过程中会不断调整，变得越来越有意义

---

## 幻灯片 9: GCN如何工作 - 信息传播
**图卷积的过程（通俗解释）：**

**第0层（初始状态）：**
- 每个用户和商品都有自己的初始向量

**第1层（听取邻居意见）：**
- 每个节点看看它的邻居都是什么样的
- 用户节点：聚合它购买过的所有商品的向量
- 商品节点：聚合购买过它的所有用户的向量
- 生成新的向量表示

**第2层（听取邻居的邻居）：**
- 继续聚合，信息传播得更远
- 现在能捕捉到"间接关系"

**第3层（更广范围）：**
- 再次聚合，覆盖更大范围的网络

**最终：**
- 把0层、1层、2层、3层的向量取平均
- 得到最终的用户向量和商品向量

---

## 幻灯片 10: GCN的数学表达（简化版）
**核心公式：**
```
新向量 = 邻居向量的加权平均
```

**具体来说：**
- 假设用户A购买过商品1、商品2、商品3
- 用户A的新向量 = (商品1向量 + 商品2向量 + 商品3向量) / 3
- 同时，每个商品也会根据购买过它的用户更新向量

**归一化技巧：**
- 为了防止有些节点的邻居太多，有些太少
- 我们会对每个节点的"影响力"进行归一化处理
- 确保每个节点的贡献都在合理范围内

**多层聚合：**
- 第1层：捕捉1步之内的邻居关系
- 第2层：捕捉2步之内的关系
- 第3层：捕捉3步之内的关系
- 最后取平均，综合不同层次的信息

---

## 幻灯片 11: GCN的优势
**为什么GCN对推荐系统有效？**

1. **捕捉高阶关系**
   - 不仅考虑直接交互，还考虑间接影响
   - 例如：用户A → 商品X → 用户B → 商品Y，发现Y可能适合A

2. **缓解数据稀疏**
   - 即使用户只购买过很少的商品
   - 通过图结构，可以从相似用户那里获得信息

3. **参数共享**
   - 所有节点使用相同的聚合规则
   - 减少需要学习的参数，不容易过拟合

4. **端到端学习**
   - 嵌入向量会在训练过程中自动调整
   - 不需要人工设计特征

---

## 幻灯片 12: 如何训练模型？从评分到排序
**传统方法的问题：**
- 很多推荐场景没有评分数据
- 我们的数据只有"买过"和"没买过"
- 这叫做"隐式反馈"

**我们的思路转变：**
- 不预测评分（比如用户会给这个商品打几分）
- 而是学习排序（比如用户更喜欢商品A还是商品B）

**核心假设：**
- 用户买过的商品 > 用户没买过的商品
- 这个假设虽然简单，但很有效

---

## 幻灯片 13: BPR损失函数 - 基本思想
**BPR = Bayesian Personalized Ranking（贝叶斯个性化排序）**

**目标：**
- 让模型学会正确排序：用户更喜欢的商品应该排在前面

**如何实现？**
- 对于每个用户，我们采样两个商品：
  - 正样本：用户购买过的商品
  - 负样本：用户没购买过的商品
- 希望模型对正样本的评分 > 负样本的评分

**训练过程：**
- 如果模型预测正确（正样本分数高），损失小
- 如果模型预测错误（负样本分数高），损失大
- 通过不断调整，让模型的预测越来越准确

---

## 幻灯片 14: BPR损失函数 - 数学表达
**评分计算：**
```
用户u对商品i的评分 = sigmoid(用户u向量 · 商品i向量)
```
- "·" 表示向量点积（两个向量对应位置相乘再相加）
- sigmoid函数把结果压缩到0-1之间
- 分数越接近1，表示用户越可能喜欢这个商品

**BPR损失：**
```
损失 = -log(sigmoid(正样本评分 - 负样本评分))
```

**直观理解：**
- 如果正样本评分 >> 负样本评分：损失很小（模型做得好）
- 如果正样本评分 ≈ 负样本评分：损失适中（模型不确定）
- 如果正样本评分 < 负样本评分：损失很大（模型做错了）

**简化版：**
```
损失 = mean(softplus(负样本评分 - 正样本评分))
```
- softplus是一个平滑函数，类似于max(0, x)
- 惩罚那些负样本评分高于正样本的情况

---

## 幻灯片 15: 正则化 - 防止模型"作弊"
**什么是过拟合？**
- 模型在训练数据上表现很好
- 但在新数据上表现很差
- 就像死记硬背，没有真正理解

**L2正则化的作用：**
- 限制嵌入向量不要太大
- 鼓励模型学习简单、通用的模式

**正则化损失：**
```
正则损失 = (用户向量² + 正样本向量² + 负样本向量²) / (2 × batch大小)
```

**总损失：**
```
总损失 = BPR损失 + λ × 正则损失
```
- λ是一个很小的数（0.0001），控制正则化的强度

---

## 幻灯片 16: 训练流程总结
**完整的训练步骤：**

1. **数据准备**
   - 对于每个用户，采样一个正样本（购买过的商品）
   - 随机采样一个负样本（没购买过的商品）
   - 形成三元组：(用户, 正样本商品, 负样本商品)

2. **前向传播**
   - 通过GCN计算所有用户和商品的嵌入向量
   - 计算正样本和负样本的评分

3. **计算损失**
   - BPR损失：惩罚负样本评分高于正样本的情况
   - 正则化损失：防止向量过大

4. **反向传播**
   - 计算梯度（损失对每个参数的影响）
   - 使用Adam优化器更新参数

5. **迭代**
   - 重复以上步骤500轮（epochs）
   - 每10轮测试一次模型效果

---

## 幻灯片 17: 如何评估模型好不好？
**评估指标：**

**Recall@20（召回率）**
- 问题：在推荐的前20个商品中，有多少是用户真正喜欢的？
- 计算：(推荐列表中用户喜欢的商品数) / (用户喜欢的总商品数)
- 例如：用户喜欢5个商品，推荐了20个，其中3个命中 → Recall@20 = 3/5 = 0.6

**Precision@20（精确率）**
- 问题：推荐的前20个商品中，有多少比例是用户真正喜欢的？
- 计算：(推荐列表中用户喜欢的商品数) / 20
- 例如：推荐20个，命中3个 → Precision@20 = 3/20 = 0.15

**NDCG@20（归一化折损累积增益）**
- 考虑推荐顺序的质量
- 相关商品排在前面，分数更高
- 分数在0-1之间，越高越好

---

## 幻灯片 18: 实验数据集
**Last.fm数据集：**
- 来源：用户-商品交互数据
- 用户数：1,892个用户
- 商品数：4,489个商品
- 训练交互：42,135条（用户-商品对）
- 测试交互：10,533条（用于评估）

**数据特点：**
- 非常稀疏：只有0.62%的用户-商品对有交互
- 这是推荐系统的典型特征
- 大部分用户只购买过很少一部分商品

**数据划分：**
- 80%用于训练（学习用户偏好）
- 20%用于测试（评估推荐效果）

---

## 幻灯片 19: 模型的超参数设置
**什么是超参数？**
- 需要人工设定的参数（不是模型自己学习的）
- 会影响模型的性能和训练速度

**我们的设置：**
- **嵌入维度**：64（每个用户/商品用64个数字表示）
- **GCN层数**：3层（信息传播3步）
- **学习率**：0.001（参数更新的步长）
- **Batch大小**：2048（每次处理2048个样本）
- **正则化系数**：0.0001（防止过拟合的强度）
- **训练轮数**：500轮

**这些参数是如何选择的？**
- 通过实验和调试
- 在性能和计算成本之间取得平衡

---

## 幻灯片 20: 模型的工作流程图
**从数据到推荐的完整流程：**

```
1. 输入数据
   ↓
2. 构建用户-商品二部图
   ↓
3. 初始化嵌入向量（用户 + 商品）
   ↓
4. GCN信息传播（3层）
   第1层：聚合1步邻居
   第2层：聚合2步邻居  
   第3层：聚合3步邻居
   ↓
5. 层聚合（取平均）
   ↓
6. 得到最终嵌入向量
   ↓
7. 计算评分（用户向量 · 商品向量）
   ↓
8. 训练阶段：使用BPR损失优化
   或
   推荐阶段：对所有商品排序，返回Top-20
```

---

## 幻灯片 21: GCN vs 传统方法的对比
**传统协同过滤：**
- ✓ 简单易懂
- ✗ 只考虑1步关系
- ✗ 数据稀疏时效果差
- ✗ 无法捕捉复杂模式

**矩阵分解：**
- ✓ 经典有效
- ✓ 可扩展性好
- ✗ 忽略图结构信息
- ✗ 高阶关系建模能力弱

**基于GCN的方法（我们的方法）：**
- ✓ 利用图结构信息
- ✓ 捕捉高阶关系（多步传播）
- ✓ 缓解数据稀疏问题
- ✓ 端到端学习，效果更好
- ✗ 计算复杂度较高
- ✗ 需要构建和存储图结构

---

## 幻灯片 22: 为什么这个方法有效？
**关键成功因素：**

1. **图结构的力量**
   - 社交网络研究表明：相似的人会聚集在一起
   - 我们的假设：相似的用户会购买相似的商品
   - GCN正好能捕捉这种网络效应

2. **多层信息聚合**
   - 不同层次捕捉不同范围的信息
   - 第1层：直接偏好
   - 第2-3层：间接影响
   - 综合起来，理解更全面

3. **BPR的排序学习**
   - 不需要精确的评分，只需要相对偏好
   - 更符合推荐系统的实际需求
   - 对隐式反馈数据特别有效

4. **正则化的平衡**
   - 防止模型过度拟合训练数据
   - 学习泛化能力强的模式

---

## 幻灯片 23: 实际应用中的扩展思路
**这个方法可以用在哪里？**

1. **电商推荐**
   - 用户-商品图
   - 推荐用户可能购买的商品

2. **社交网络**
   - 用户-用户图
   - 推荐可能认识的朋友

3. **新闻推荐**
   - 用户-新闻图
   - 推荐用户可能感兴趣的文章

4. **视频推荐**
   - 用户-视频图
   - 推荐用户可能喜欢的视频

**可以添加的额外信息：**
- 节点属性：用户年龄、商品类别
- 边属性：购买次数、浏览时长
- 时间信息：最近的行为更重要

---

## 幻灯片 24: 这个项目的教学价值
**通过这个项目，我们学到了：**

1. **图神经网络的基本思想**
   - 信息在图上的传播
   - 邻居聚合机制
   - 多层表示学习

2. **推荐系统的核心问题**
   - 如何处理稀疏数据
   - 如何利用隐式反馈
   - 如何学习用户偏好

3. **深度学习的实践技巧**
   - 嵌入表示
   - 损失函数设计
   - 正则化方法
   - 评估指标选择

4. **从理论到实践**
   - 将图论概念应用到实际问题
   - 将数学公式转化为代码
   - 训练和调试深度学习模型

---

## 幻灯片 25: 代码实现的关键部分
**三个核心函数：**

1. **`computer()` - GCN前向传播**
   - 输入：图结构 + 初始嵌入
   - 过程：多层图卷积 + 层聚合
   - 输出：最终的用户和商品嵌入

2. **`bpr_loss()` - BPR损失计算**
   - 输入：用户、正样本、负样本
   - 过程：计算评分差 + softplus
   - 输出：BPR损失 + 正则化损失

3. **`getUsersRating()` - 评分预测**
   - 输入：用户列表
   - 过程：向量点积 + sigmoid
   - 输出：用户对所有商品的评分

**训练循环：**
- 500轮迭代
- 每轮：采样 → 计算损失 → 更新参数
- 每10轮：在测试集上评估

---

## 幻灯片 26: 常见问题解答

**Q1: 为什么要用图？不能直接用神经网络吗？**
- A: 图能表示用户-商品之间的关系结构，这是普通神经网络无法捕捉的。GCN能利用这种结构信息，效果更好。

**Q2: 负样本怎么选？随机选择合理吗？**
- A: 本项目使用随机负采样。更高级的方法会选择"困难负样本"（模型容易混淆的），但随机采样已经足够有效。

**Q3: 为什么要多层聚合而不是只用最后一层？**
- A: 不同层次捕捉不同范围的信息。只用最后一层可能过于全局，丢失局部特征。平均所有层能平衡局部和全局信息。

**Q4: 这个模型能用在冷启动问题上吗？**
- A: 对于新用户（没有任何交互记录），这个模型效果有限。需要结合基于内容的方法或利用用户属性。

---

## 幻灯片 27: 可能的改进方向

**模型改进：**
1. **注意力机制**
   - 不是简单平均邻居，而是学习邻居的重要性权重
   - 更重要的邻居应该有更大的影响

2. **时间信息**
   - 考虑用户兴趣随时间的变化
   - 最近的行为应该有更大的权重

3. **多任务学习**
   - 同时优化多个目标（点击、播放时长等）
   - 提升模型的泛化能力

**工程改进：**
1. **负采样策略**
   - 困难负样本挖掘
   - 流行度偏差校正

2. **模型压缩**
   - 知识蒸馏
   - 嵌入维度降低
   - 加快推理速度

---

## 幻灯片 28: 总结
**核心要点回顾：**

1. **问题：** 为用户推荐可能喜欢但还没购买过的商品

2. **方法：** 
   - 用图表示用户-商品关系
   - 用GCN学习嵌入向量
   - 用BPR损失优化排序

3. **GCN的作用：**
   - 在图上传播信息
   - 捕捉多步关系
   - 缓解数据稀疏

4. **BPR的作用：**
   - 学习正确的排序
   - 适合隐式反馈
   - 优化推荐质量

5. **效果评估：**
   - Recall：能找回多少用户喜欢的
   - Precision：推荐有多准确
   - NDCG：排序质量如何

---

## 幻灯片 29: 参考文献与延伸阅读
**核心论文：**

1. **LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation**
   - 简化的GCN架构，专为推荐系统设计
   - SIGIR 2020

2. **BPR: Bayesian Personalized Ranking from Implicit Feedback**
   - BPR损失函数的原始论文
   - UAI 2009

3. **Semi-Supervised Classification with Graph Convolutional Networks**
   - GCN的基础论文
   - ICLR 2017

**相关概念：**
- 协同过滤（Collaborative Filtering）
- 隐式反馈（Implicit Feedback）
- 图神经网络（Graph Neural Networks）
- 成对排序（Pairwise Ranking）

---

## 幻灯片 30: 谢谢！
**感谢聆听！**

**项目信息：**
- GitHub: [项目链接]
- 数据集: Last.fm
- 框架: PyTorch

**问题与讨论**
- 欢迎提问！
- 欢迎交流探讨！

---

## 附录：专业术语对照表

| 中文 | 英文 | 简单解释 |
|------|------|----------|
| 图卷积网络 | Graph Convolutional Network (GCN) | 在图上进行卷积操作的神经网络 |
| 贝叶斯个性化排序 | Bayesian Personalized Ranking (BPR) | 一种学习排序的损失函数 |
| 嵌入向量 | Embedding | 用数字向量表示对象的方法 |
| 二部图 | Bipartite Graph | 节点可分为两组，连边只在两组之间 |
| 稀疏 | Sparse | 大部分位置没有值的数据 |
| 正则化 | Regularization | 防止模型过拟合的技术 |
| 隐式反馈 | Implicit Feedback | 没有明确评分，只有行为数据 |
| 协同过滤 | Collaborative Filtering | 基于群体行为的推荐方法 |
| 召回率 | Recall | 找回相关项目的比例 |
| 精确率 | Precision | 推荐准确的比例 |
